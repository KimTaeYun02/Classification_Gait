{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a12cf33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eadfba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_keypoints(frame, net, threshold, BODY_PARTS, now_frame, total_frame):\n",
    "    global points\n",
    "\n",
    "    # 입력 이미지의 사이즈 정의\n",
    "    image_height = 480\n",
    "    image_width = 854\n",
    "\n",
    "    # 네트워크에 넣기 위한 전처리\n",
    "    input_blob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (image_width, image_height), (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "    # 전처리된 blob 네트워크에 입력\n",
    "    net.setInput(input_blob)\n",
    "\n",
    "    # 결과 받아오기\n",
    "    out = net.forward()\n",
    "    # The output is a 4D matrix :\n",
    "    # The first dimension being the image ID ( in case you pass more than one image to the network ).\n",
    "    # The second dimension indicates the index of a keypoint.\n",
    "    # The model produces Confidence Maps and Part Affinity maps which are all concatenated.\n",
    "    # For COCO model it consists of 57 parts – 18 keypoint confidence Maps + 1 background + 19*2 Part Affinity Maps. Similarly, for MPI, it produces 44 points.\n",
    "    # We will be using only the first few points which correspond to Keypoints.\n",
    "    # The third dimension is the height of the output map.\n",
    "    out_height = out.shape[2]\n",
    "    # The fourth dimension is the width of the output map.\n",
    "    out_width = out.shape[3]\n",
    "\n",
    "    # 원본 이미지의 높이, 너비를 받아오기\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    # 포인트 리스트 초기화\n",
    "    points = []\n",
    "\n",
    "    print(f\"============================== frame: {now_frame:.0f} / {total_frame:.0f} ==============================\")\n",
    "    for i in range(len(BODY_PARTS)):\n",
    "\n",
    "        # 신체 부위의 confidence map\n",
    "        prob_map = out[0, i, :, :]\n",
    "\n",
    "        # 최소값, 최대값, 최소값 위치, 최대값 위치\n",
    "        min_val, prob, min_loc, point = cv2.minMaxLoc(prob_map)\n",
    "\n",
    "        # 원본 이미지에 맞게 포인트 위치 조정\n",
    "        x = (frame_width * point[0]) / out_width\n",
    "        x = int(x)\n",
    "        y = (frame_height * point[1]) / out_height\n",
    "        y = int(y)\n",
    "\n",
    "        if prob > threshold:  # [pointed]\n",
    "            cv2.circle(frame, (x, y), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frame, str(i), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "            points.append((x, y))\n",
    "            print(f\"[pointed] {BODY_PARTS[i]} ({i}) => prob: {prob:.5f} / x: {x} / y: {y}\")\n",
    "\n",
    "        else:  # [not pointed]\n",
    "            cv2.circle(frame, (x, y), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frame, str(i), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "            points.append(None)\n",
    "            print(f\"[not pointed] {BODY_PARTS[i]} ({i}) => prob: {prob:.5f} / x: {x} / y: {y}\")\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42de52b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_keypoints_with_lines(frame, POSE_PAIRS):\n",
    "    for pair in POSE_PAIRS:\n",
    "        part_a = pair[0]  # 0 (Head)\n",
    "        part_b = pair[1]  # 1 (Neck)\n",
    "        if points[part_a] and points[part_b]:\n",
    "            print(f\"[linked] {part_a} {points[part_a]} <=> {part_b} {points[part_b]}\")\n",
    "            cv2.line(frame, points[part_a], points[part_b], (0, 255, 0), 3)\n",
    "        else:\n",
    "            print(f\"[not linked] {part_a} {points[part_a]} <=> {part_b} {points[part_b]}\")\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f33126c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_keypoints_with_lines_video(proto_file, weights_file, video_path, threshold, BODY_PARTS, POSE_PAIRS):\n",
    "\n",
    "    # 네트워크 불러오기\n",
    "    net = cv2.dnn.readNetFromCaffe(proto_file, weights_file)\n",
    "    \n",
    "    # GPU 사용\n",
    "    # net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "    # net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "    # 비디오 읽어오기\n",
    "    capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "    while True:\n",
    "        now_frame_boy = capture.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "        total_frame_boy = capture.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "        if now_frame_boy == total_frame_boy:\n",
    "            break\n",
    "\n",
    "        ret, frame_boy = capture.read()\n",
    "        frame_boy = output_keypoints(frame=frame_boy, net=net, threshold=threshold, BODY_PARTS=BODY_PARTS, now_frame=now_frame_boy, total_frame=total_frame_boy)\n",
    "        frame_boy = output_keypoints_with_lines(frame=frame_boy, POSE_PAIRS=POSE_PAIRS)\n",
    "        cv2.imshow(\"Output_Keypoints\", frame_boy)\n",
    "\n",
    "        if cv2.waitKey(10) == 27:  # esc 입력시 종료\n",
    "            break\n",
    "\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc53b54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BODY_PARTS_MPI = {0: \"Head\", 1: \"Neck\", 2: \"RShoulder\", 3: \"RElbow\", 4: \"RWrist\",\n",
    "                  5: \"LShoulder\", 6: \"LElbow\", 7: \"LWrist\", 8: \"RHip\", 9: \"RKnee\",\n",
    "                  10: \"RAnkle\", 11: \"LHip\", 12: \"LKnee\", 13: \"LAnkle\", 14: \"Chest\",\n",
    "                  15: \"Background\"}\n",
    "\n",
    "POSE_PAIRS_MPI = [[0, 1], [1, 2], [1, 5], [1, 14], [2, 3], [3, 4], [5, 6],\n",
    "                  [6, 7], [8, 9], [9, 10], [11, 12], [12, 13], [14, 8], [14, 11]]\n",
    "\n",
    "BODY_PARTS_COCO = {0: \"Nose\", 1: \"Neck\", 2: \"RShoulder\", 3: \"RElbow\", 4: \"RWrist\",\n",
    "                   5: \"LShoulder\", 6: \"LElbow\", 7: \"LWrist\", 8: \"RHip\", 9: \"RKnee\",\n",
    "                   10: \"RAnkle\", 11: \"LHip\", 12: \"LKnee\", 13: \"LAnkle\", 14: \"REye\",\n",
    "                   15: \"LEye\", 16: \"REar\", 17: \"LEar\", 18: \"Background\"}\n",
    "\n",
    "POSE_PAIRS_COCO = [[0, 1], [0, 14], [0, 15], [1, 2], [1, 5], [1, 8], [1, 11], [2, 3], [3, 4],\n",
    "                   [5, 6], [6, 7], [8, 9], [9, 10], [12, 13], [11, 12], [14, 16], [15, 17]]\n",
    "\n",
    "BODY_PARTS_BODY_25 = {0: \"Nose\", 1: \"Neck\", 2: \"RShoulder\", 3: \"RElbow\", 4: \"RWrist\",\n",
    "                      5: \"LShoulder\", 6: \"LElbow\", 7: \"LWrist\", 8: \"MidHip\", 9: \"RHip\",\n",
    "                      10: \"RKnee\", 11: \"RAnkle\", 12: \"LHip\", 13: \"LKnee\", 14: \"LAnkle\",\n",
    "                      15: \"REye\", 16: \"LEye\", 17: \"REar\", 18: \"LEar\", 19: \"LBigToe\",\n",
    "                      20: \"LSmallToe\", 21: \"LHeel\", 22: \"RBigToe\", 23: \"RSmallToe\", 24: \"RHeel\", 25: \"Background\"}\n",
    "\n",
    "POSE_PAIRS_BODY_25 = [[0, 1], [0, 15], [0, 16], [1, 2], [1, 5], [1, 8], [8, 9], [8, 12], [9, 10], [12, 13], [2, 3],\n",
    "                      [3, 4], [5, 6], [6, 7], [10, 11], [13, 14], [15, 17], [16, 18], [14, 21], [19, 21], [20, 21],\n",
    "                      [11, 24], [22, 24], [23, 24]]\n",
    "\n",
    "# 신경 네트워크의 구조를 지정하는 prototxt 파일 (다양한 계층이 배열되는 방법 등)\n",
    "#protoFile_mpi = \"pose/mpi/pose_deploy_linevec.prototxt\"\n",
    "#protoFile_mpi_faster = \"pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "#protoFile_coco = \"pose/coco/pose_deploy_linevec.prototxt\"\n",
    "protoFile_body_25 = \"body25/pose_deploy.prototxt\"\n",
    "\n",
    "# 훈련된 모델의 weight 를 저장하는 caffemodel 파일\n",
    "#weightsFile_mpi = \"pose/mpi/pose_iter_160000.caffemodel\"\n",
    "#weightsFile_coco = \"pose/coco/pose_iter_440000.caffemodel\"\n",
    "weightsFile_body_25 = \"body25/pose_iter_584000.caffemodel\"\n",
    "\n",
    "\n",
    "# 비디오 경로\n",
    "man = \"walk.mp4\"\n",
    "\n",
    "# 키포인트를 저장할 빈 리스트\n",
    "points = []\n",
    "\n",
    "#output_keypoints_with_lines_video(proto_file=protoFile_mpi_faster, weights_file=weightsFile_mpi, video_path=man,threshold=0.1, BODY_PARTS=BODY_PARTS_MPI, POSE_PAIRS=POSE_PAIRS_MPI)\n",
    "\n",
    "#output_keypoints_with_lines_video(proto_file=protoFile_coco, weights_file=weightsFile_coco, video_path=man,threshold=0.1, BODY_PARTS=BODY_PARTS_COCO, POSE_PAIRS=POSE_PAIRS_COCO)\n",
    "\n",
    "output_keypoints_with_lines_video(proto_file=protoFile_body_25, weights_file=weightsFile_body_25, video_path=man,\n",
    "                                  threshold=0.1, BODY_PARTS=BODY_PARTS_BODY_25, POSE_PAIRS=POSE_PAIRS_BODY_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1813082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db9e9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
